Форк https://github.com/lpigeon/ros-mcp-server

Переработан функционал под специфику робота AiNex

# AiNex под управлением LLM

Превращаем робота в понятный и доступный инструмент с помощью MCP  сервера!

## Ключевые обновления

### Обновлен способ подключения к ROS.
Исправлены ошибки с вызовами методов подключения через WEB-socet.
Web-socet менеджер переписан на основе библиотеки roslibPY через стандартные методы, например
```python
topic = roslibpy.Topic( self.ws, topic, topic_data_type )
```
Вместо обычного сетевого взаимодействия в оригинале через JSON
```python
# Ensure message is JSON serializable
json_msg = json.dumps(message)
self.ws.send(json_msg)
```
### Добавлен голосовой агент для бесшовного управления.
Голосовой агент вынесен в отдельный питон файл – voice_agent.py для запуска как на самом роботе, так и на отдельной станции.

Выполнено обучение активации по голосой команде “AiNex” с помощью Porcupine Wake Word Python API. Подготовлены модели для запуска на ПК под Windows и на Raspbery PI5 робота:
* Ai-Nex_en_raspberry-pi_v3_0_0.ppn
* Ai-ex_en_windows_v3_0_0.ppn

При сборке укажите подходящую для выбранной платформы.

Wake Word обеспечивает оперативную реакцию на обращение к роботу с минимум ресурсов.

После активации, производится запись и распознавание обращения к роботу через пакет SpeechRecognition

Далее, текстовая интерпретация запроса пользователя передается в LLM. Предварительно формируется системный промт и опционально сохраняется история чата для контекста (фалг history_active). Голосовое распознавание может быть отключено и выбран режим текстового чата через флаг text_input (true для выключения голосового ввода).

Работа с LLM осуществляется через API together (https://together.ai/), может быть выбрана любая доступная для вашего API ключа модель.

Озвучивание ответов реализовано через gTTS.

Для уменьшения времени задержки, добавлено кэширование уже озвученных ранее ответов в рамках сессии.
Проводится проверка хэша ответа LLM и в случае наличия такого в кэше воспроизводится локальная запись.

### MCP передает в контекст LLM созданные в родном приложении AiNex Action group файлы.
Теперь LLM может получить доступ к ранее созданным в редакторе файлам с действиями робота (ActionGroups) и вызывать их в соответствии с контекстом. Для этого реализован инструмент в MCP сервере get_available_actions()
### Дополнительные инструменты MCP
* Изменен инструмент get_image() метод для работы на ПК и сохранением картинки в загрузки.
* Добавлен метод make_step(x: float, z: float): В соответствии с моделью управления роботом AiNex через джойстик.
* Добавлен метод run_action(action_name: str): для вызова ранее запрошенных действий по имени.

Важно давать подготовленным действиям понятные именна, дял адекватног овосприятия контекста LLM. Если сделат ьвсе правильно, ИИ сможет вызвать нужное действие по описанию или по ситуации, не требуя от пользователя точного названия.

## Вам понадобятся API ключи!

Для https://together.ai/ и https://console.picovoice.ai/ (быстрая активация голосом). К счастью их можно получить бесплатно зарегистрировавшись на сайтах.

Ключи передаются через переменные окружения во время запуска.

## Быстрый старт

Запустите на роботе файл ROS/action\_groups.py для публикации актуальных действий, сначала на робота потом в docker

```bash
docker cp action_groups.py ainex:/home/ubuntu/ros_ws/src
```

Теперь на роботе или ПК разверните MCP сервер (ПК должен находиться в 1 сети с роботом или придется подключить к роботу микрофон. При необходимости поправьте ROS IP для работы по сети.

MCP общается с агентом через STDIO, поэтому достаточно вызвать голосового агента, он сам запустит сервер.

Для удобства установки пакетов используется UV

Чтобы запустить все используйте шаблонный bat fileдобавив в него ваши API ключи

```bash
set TOGETHER_API_KEY=Ваш ключ
set WAKEUP_API_KEY=Ваш ключ
uv run voice_agent.py
```

При 1 запуске установятся необходимые пакеты

Теперь вы готовы открыть вашего робота по новому с LLM!
